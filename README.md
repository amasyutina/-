# Лабораторные работы
## Исполнительные компоненты CUDA-устройства

### Стриминговые мультипроцессоры (Streaming Multiprocessors, SM)

• Определение: Стриминговые мультипроцессоры — это основные вычислительные единицы в архитектуре CUDA, которые обрабатывают потоки данных.
• Пояснение: Каждый SM содержит множество вычислительных ядер, которые могут выполнять параллельные операции над данными. SM управляет выполнением блоков потоков и распределяет ресурсы между ними, что позволяет эффективно использовать вычислительные мощности GPU.

### Вычислительные юниты (Compute Units)

• Определение: Вычислительные юниты — это отдельные ядра внутри SM, которые выполняют арифметические и логические операции.
• Пояснение: Эти юниты обрабатывают инструкции от потоков и могут выполнять операции над числами, такие как сложение, умножение и другие. Количество вычислительных юнитов в SM зависит от архитектуры GPU.

### Модель выполнения ядра

• Определение: Модель выполнения ядра описывает, как потоки организуются и выполняются на GPU.
• Пояснение: Ядро CUDA — это функция, которая запускается на GPU и состоит из множества потоков, сгруппированных в блоки. Каждый блок потоков может выполняться на одном SM, что позволяет эффективно распределять вычисления и использовать ресурсы.

### Потоки и отображение блоков потоков на процессорные элементы

1. Потоки (Threads)

• Определение: Потоки — это наименьшие единицы выполнения в CUDA, которые могут выполняться параллельно.
• Пояснение: Каждый поток имеет свои собственные регистры и локальную память, что позволяет им работать независимо друг от друга. Потоки могут взаимодействовать через общую память, но должны быть синхронизированы для предотвращения конфликтов.

2. Отображение блоков потоков на процессорные элементы

• Определение: Отображение блоков потоков — это процесс распределения блоков потоков по доступным SM на GPU.
• Пояснение: Блоки потоков распределяются по SM в зависимости от их ресурсов (например, количество регистров и памяти). Это позволяет оптимизировать использование вычислительных мощностей и повышает производительность.

### Варпы и переключение варпов

1 Варпы (Warps)

• Определение: Варп — это группа из 32 потоков, которые обрабатываются одновременно на одном SM.
• Пояснение: Все потоки в варпе выполняют одну и ту же инструкцию одновременно, что позволяет эффективно использовать ресурсы SM. Если один поток в варпе блокируется (например, ожидает данные), остальные потоки продолжают выполнение, что минимизирует простои.

2 Переключение варпов

• Определение: Переключение варпов — это процесс переключения между различными варпами для оптимизации использования ресурсов.
• Пояснение: Когда один варп блокируется, SM может переключиться на другой варп, чтобы избежать простаивания ресурсов. Это увеличивает общую производительность за счет более эффективного использования вычислительных мощностей.

### Синхронизация

1 Синхронизация (Synchronization)

• Определение: Синхронизация — это механизм, который обеспечивает согласованность данных между потоками.
• Пояснение: В CUDA существуют механизмы синхронизации, такие как __syncthreads(), который синхронизирует потоки внутри одного блока. Это необходимо для обеспечения правильного доступа к данным, когда потоки взаимодействуют друг с другом.

##  Типы памяти в архитектуре CUDA

1. Глобальная память (Global Memory)

• Описание: Глобальная память доступна всем потокам и блокам на устройстве. Это основная память GPU, где хранятся данные, передаваемые из хоста.
• Размер: Обычно очень большая (может достигать гигабайтов).
• Скорость доступа: Доступ к глобальной памяти относительно медленный по сравнению с другими типами памяти.
• Оптимизация: Для повышения производительности рекомендуется минимизировать количество обращений к глобальной памяти и использовать коалесцированный доступ (групповой доступ к данным).

2. Общая память (Shared Memory)

• Описание: Общая память доступна для всех потоков в одном блоке и используется для обмена данными между потоками.
• Размер: Ограниченный (обычно несколько килобайт на блок).
• Скорость доступа: Очень быстрая, так как она находится на уровне блока и имеет низкую задержку.
• Оптимизация: Эффективное использование общей памяти может значительно ускорить выполнение программы. Рекомендуется использовать её для хранения часто используемых данных и для уменьшения обращений к глобальной памяти.
